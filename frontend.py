import os
import re
import tempfile
import streamlit as st
import nltk
from dotenv import load_dotenv
from backend import store_embeddings, query_chatbot

# Ensure nltk is ready
try:
    nltk.data.find('corpora/averaged_perceptron_tagger')
except LookupError:
    nltk.download('averaged_perceptron_tagger')

# Load environment variables
load_dotenv()
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
GROQ_API_KEY = os.getenv("GROQ_API_KEY")  # Add this line
PINECONE_INDEX_NAME = "medical"

# Streamlit page setup
st.set_page_config(page_title="Medical-Bot", layout="wide")
st.title("ğŸ©º Medical-Bot - AI-powered Medical Assistant")

# Verify API keys
if not GROQ_API_KEY:
    st.error("âš ï¸ Groq API key not found. Please add GROQ_API_KEY to your .env file.")
    st.stop()

if not PINECONE_API_KEY:
    st.error("âš ï¸ Pinecone API key not found. Please add PINECONE_API_KEY to your .env file.")
    st.stop()

# Model selection in sidebar
st.sidebar.header("Model Settings")
model_choice = st.sidebar.selectbox(
    "Select Groq Model:",
    ["mixtral-8x7b-32768", "llama2-70b-4096"]
)

# Data Source Selection
st.sidebar.header("Data Source Selection")
data_source = st.sidebar.radio("Choose data source:", ["Upload a PDF", "Enter a URL", "Use Default Data"])

pdf_file = None
url_input = ""

def is_valid_url(url):
    pattern = re.compile(r"^(https?://)?(www\.)?[\w-]+(\.[\w-]+)+[/#?]?.*$")
    return re.match(pattern, url)

if data_source == "Upload a PDF":
    pdf_file = st.sidebar.file_uploader("ğŸ“‚ Upload a PDF file", type=["pdf"])
elif data_source == "Enter a URL":
    url_input = st.sidebar.text_input("ğŸ”— Paste a URL:")
elif data_source == "Use Default Data":
    st.sidebar.write("ğŸ“š Using preloaded medical data.")

# Initialize session state for chat history
if "queries" not in st.session_state:
    st.session_state.queries = []

# Process Data Button with Loading Indicator
if st.sidebar.button("âš¡ Process Data"):
    with st.spinner("ğŸ“„ Processing data... Please wait!"):
        try:
            if pdf_file:
                with tempfile.NamedTemporaryFile(delete=False) as tmp_file:
                    tmp_file.write(pdf_file.read())
                    result = store_embeddings(tmp_file.name)
                    st.sidebar.success("âœ… PDF processed successfully!")
            elif url_input:
                if is_valid_url(url_input):
                    result = store_embeddings(url_input)
                    st.sidebar.success("âœ… URL processed successfully!")
                else:
                    st.sidebar.error("âŒ Invalid URL! Please enter a valid URL.")
            elif data_source == "Use Default Data":
                result = store_embeddings("Medical_book.pdf")
                st.sidebar.success("âœ… Default data processed!")
        except Exception as e:
            st.sidebar.error(f"âŒ Error processing data: {str(e)}")

# Ask a medical question
st.header("ğŸ¤– Ask Your Medical Question")
question = st.text_area("Type your query below:")

if st.button("ğŸ’¬ Submit Query") and question:
    with st.spinner("ğŸ¤” Generating response... Please wait!"):
        try:
            response = query_chatbot(question, model=model_choice)
            st.session_state.queries.append((question, response))
        except Exception as e:
            st.error(f"âŒ Error generating response: {str(e)}")

# Display previous queries in a Chat-style UI
st.subheader("ğŸ’¬ Chat History")
for idx, (q, r) in enumerate(st.session_state.queries):
    with st.chat_message("user"):
        st.write(f"**You:** {q}")
    with st.chat_message("assistant"):
        st.write(f"**Bot:** {r}")

# Footer
st.markdown("---")
st.markdown("ğŸ” **Medical-Bot** - AI-powered assistant for medical information powered by Groq ğŸ’¡")
